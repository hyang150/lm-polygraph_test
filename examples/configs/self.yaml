# Hydra 全局配置
hydra:
  run:
    dir: ${cache_path}/${task}/${model_name}/${dataset_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - estimators: default_estimators
  - stat_calculators: default_calculators
  - _self_

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

task: qa

dataset: ['LM-Polygraph/mmlu', 'continuation']

text_column: input
label_column: output

train_split: train
eval_split: test

size: 10000
subsample_eval_dataset: -1

# 模型配置：使用 Llama 3.1 8B 模型
model:
  path: "meta-llama/Llama-3.1-8B"  # 模型路径，请根据实际情况更新
  device_map: "cuda:0"             # 有 GPU 则使用 "cuda:0"，否则 "cpu"

# 可选：若使用 CSV 作为数据集评估，请开启下面的配置
eval_dataset:
  _target_: lm_polygraph.datasets.CSVDataset
  path: "/workspace/test/lm-polygraph_test/all_true_false_combined.csv"  # CSV 文件的完整路径
  input_key: "statement"
  reference_key: "label"

uncertainty_estimators:
  - name: "mean_pointwise_mutual_information"
  - name: "perplexity"
  - name: "mean_token_entropy"
  - name: "max_token_entropy"

generation_params:
  generate_until:
    - "\n"

generation:
  do_sample: false
  num_beams: 1
  temperature: 1.0

max_new_tokens: 64

generation_metrics: null

ignore_exceptions: false
batch_size: 8
load_from_disk: false

seed:
  - 1
